#!/bin/bash
# Lucendex Data Services Deployment Script
# Deploys rippled API + Full-History + PostgreSQL + Backend services to Contabo

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TERRAFORM_DIR="$SCRIPT_DIR/terraform"
DOCKER_DIR="$SCRIPT_DIR/docker"
SCRIPTS_DIR="$SCRIPT_DIR/scripts"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_step() {
    echo -e "${GREEN}[STEP]${NC} $1"
}

check_prerequisites() {
    log_info "Checking prerequisites..."
    
    local missing_tools=()
    
    if ! command -v terraform &> /dev/null; then
        missing_tools+=("terraform")
    fi
    
    if ! command -v ssh &> /dev/null; then
        missing_tools+=("ssh")
    fi
    
    if ! command -v ssh-keygen &> /dev/null; then
        missing_tools+=("ssh-keygen")
    fi
    
    if [ ${#missing_tools[@]} -gt 0 ]; then
        log_error "Missing required tools: ${missing_tools[*]}"
        log_info "Install with: brew install ${missing_tools[*]}"
        exit 1
    fi
    
    log_info "âœ“ Prerequisites check passed"
}

setup_api_key() {
    log_info "Setting up Contabo API credentials..."
    
    if [ -f "${TERRAFORM_DIR}/.envrc" ]; then
        log_info "âœ“ .envrc file already exists"
        return 0
    fi
    
    # Check if validator .envrc exists
    local validator_envrc="${SCRIPT_DIR}/../validator/terraform/.envrc"
    local client_id=""
    local client_secret=""
    local api_user=""
    local api_password=""
    
    if [ -f "$validator_envrc" ]; then
        log_info "âœ“ Found validator .envrc"
        log_info "Reusing Contabo credentials"
        client_id=$(grep "export CONTABO_CLIENT_ID=" "$validator_envrc" | cut -d'"' -f2)
        client_secret=$(grep "export CONTABO_CLIENT_SECRET=" "$validator_envrc" | cut -d'"' -f2)
        api_user=$(grep "export CONTABO_API_USER=" "$validator_envrc" | cut -d'"' -f2)
        api_password=$(grep "export CONTABO_API_PASSWORD=" "$validator_envrc" | cut -d'"' -f2)
        log_info "âœ“ Credentials loaded"
    else
        echo ""
        log_warn "Contabo API credentials required"
        log_info "Get from: https://my.contabo.com/api/details"
        echo ""
        
        read -p "Client ID: " -r client_id
        read -p "Client Secret: " -r client_secret
        read -p "API User (email): " -r api_user
        read -sp "API Password: " -r api_password
        echo ""
        
        if [ -z "$client_id" ] || [ -z "$client_secret" ] || [ -z "$api_user" ] || [ -z "$api_password" ]; then
            log_error "All credentials required"
            exit 1
        fi
        
        echo "Parsed: $client_id / $client_secret / $api_user / ****"
        echo ""
    fi
    
    # Auto-generate database passwords
    echo ""
    log_info "Generating secure database passwords..."
    
    postgres_pass=$(openssl rand -base64 32 | tr -d '/+=' | head -c 32)
    indexer_pass=$(openssl rand -base64 32 | tr -d '/+=' | head -c 32)
    router_pass=$(openssl rand -base64 32 | tr -d '/+=' | head -c 32)
    api_pass=$(openssl rand -base64 32 | tr -d '/+=' | head -c 32)
    
    log_info "âœ“ Generated 4 secure passwords (32 characters each)"
    
    # Display passwords for backup
    echo ""
    log_warn "ðŸ” SAVE THESE PASSWORDS SECURELY (shown only once):"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "PostgreSQL: $postgres_pass"
    echo "Indexer:    $indexer_pass"
    echo "Router:     $router_pass"
    echo "API:        $api_pass"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    log_warn "Passwords will be saved to .envrc (gitignored)"
    log_info "For DB access, use: make data-db-shell (no password needed)"
    echo ""
    read -p "Press Enter to continue..."
    
    log_info "Creating .envrc file..."
    cat > "${TERRAFORM_DIR}/.envrc" <<EOF
# Contabo API Configuration
# Generated on $(date)

export CONTABO_CLIENT_ID="${client_id}"
export CONTABO_CLIENT_SECRET="${client_secret}"
export CONTABO_API_USER="${api_user}"
export CONTABO_API_PASSWORD="${api_password}"

export TF_VAR_contabo_client_id="\${CONTABO_CLIENT_ID}"
export TF_VAR_contabo_client_secret="\${CONTABO_CLIENT_SECRET}"
export TF_VAR_contabo_api_user="\${CONTABO_API_USER}"
export TF_VAR_contabo_api_password="\${CONTABO_API_PASSWORD}"

export TF_VAR_postgres_password="${postgres_pass}"
export TF_VAR_indexer_db_password="${indexer_pass}"
export TF_VAR_router_db_password="${router_pass}"
export TF_VAR_api_db_password="${api_pass}"
EOF
    
    chmod 600 "${TERRAFORM_DIR}/.envrc"
    log_info "âœ“ Configuration saved"
}

generate_ssh_key() {
    log_info "SSH keys auto-generated by Terraform"
}

main() {
    log_info "Starting Data Services Deployment"
    log_info "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    
    check_prerequisites
    setup_api_key
    generate_ssh_key
    
    # Initialize and apply Terraform
    log_info ""
    log_step "Deploying infrastructure with Terraform..."
    cd "$TERRAFORM_DIR"
    
    # Source .envrc to get password values
    if [ -f ".envrc" ]; then
        source .envrc
    else
        log_error ".envrc not found after setup"
        exit 1
    fi
    
    terraform init
    terraform plan -out=tfplan
    
    read -p "Apply Terraform plan? (y/N) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_warn "Deployment cancelled"
        exit 0
    fi
    
    terraform apply tfplan

    # Get instance IP
    INSTANCE_IP=$(terraform output -raw data_services_ip)
    log_info "Instance deployed at $INSTANCE_IP"

    # Wait for instance to be ready
    log_info ""
    log_step "Waiting for instance to be ready..."
    for i in {1..60}; do
        if ssh -i data_services_ssh_key -o StrictHostKeyChecking=no -o ConnectTimeout=5 root@$INSTANCE_IP "echo ready" &> /dev/null; then
            log_info "âœ“ Instance is ready"
            break
        fi
        echo "Waiting... ($i/60)"
        sleep 10
    done

    # Run VM setup script
    log_info ""
    log_step "Running VM setup script..."
    scp -i data_services_ssh_key "$SCRIPTS_DIR/setup-vm.sh" root@$INSTANCE_IP:/tmp/
    ssh -i data_services_ssh_key root@$INSTANCE_IP "bash /tmp/setup-vm.sh"
    log_info "âœ“ VM setup complete"

    # Copy Docker configurations
    log_info ""
    log_step "Copying Docker configurations..."
    scp -i data_services_ssh_key "$DOCKER_DIR/docker-compose.yml" root@$INSTANCE_IP:/opt/lucendex/docker/
    scp -i data_services_ssh_key "$DOCKER_DIR/rippled-api.cfg" root@$INSTANCE_IP:/opt/lucendex/docker/
    scp -i data_services_ssh_key "$DOCKER_DIR/rippled-history.cfg" root@$INSTANCE_IP:/opt/lucendex/docker/
    scp -i data_services_ssh_key "$DOCKER_DIR/postgresql.conf" root@$INSTANCE_IP:/opt/lucendex/docker/
    scp -i data_services_ssh_key "$DOCKER_DIR/validators.txt" root@$INSTANCE_IP:/opt/lucendex/docker/
    scp -i data_services_ssh_key "$DOCKER_DIR/init-db.sql" root@$INSTANCE_IP:/opt/lucendex/docker/
    log_info "âœ“ Configurations copied"

    # Create .env file
    log_info ""
    log_step "Configuring environment..."
    cat > /tmp/data-services.env << EOF
POSTGRES_PASSWORD=${TF_VAR_postgres_password}
INDEXER_DB_PASSWORD=${TF_VAR_indexer_db_password}
ROUTER_DB_PASSWORD=${TF_VAR_router_db_password}
API_DB_PASSWORD=${TF_VAR_api_db_password}
EOF
    scp -i data_services_ssh_key /tmp/data-services.env root@$INSTANCE_IP:/opt/lucendex/docker/.env
    rm /tmp/data-services.env
    ssh -i data_services_ssh_key root@$INSTANCE_IP "chmod 600 /opt/lucendex/docker/.env"
    
# Setup PostgreSQL SSL volume and certificates
log_info "Setting up PostgreSQL SSL certificates..."
ssh -i data_services_ssh_key root@$INSTANCE_IP << 'EOF'
cd /opt/lucendex/docker

# Remove old volumes (fresh start)
docker volume rm docker_postgres-data docker_postgres-wal docker_postgres-ssl 2>/dev/null || true

# Create fresh volumes
docker volume create docker_postgres-data
docker volume create docker_postgres-wal
docker volume create docker_postgres-ssl

# Generate SSL cert in dedicated ssl volume
docker run --rm -v docker_postgres-ssl:/ssl alpine sh -c '
  apk add openssl && \
  openssl req -new -newkey rsa:2048 -x509 -sha256 -days 365 -nodes \
    -subj "/C=MT/ST=Malta/L=Valletta/O=Lucendex/CN=postgres.lucendex.local" \
    -keyout /ssl/server.key \
    -out /ssl/server.crt && \
  chmod 600 /ssl/server.key && \
  chmod 644 /ssl/server.crt && \
  chown 70:70 /ssl/server.*'
EOF
log_info "âœ“ SSL certificates pre-generated in dedicated volume"
    
    # Now start all services with SSL cert already in place
    log_info "Starting all services..."
    ssh -i data_services_ssh_key root@$INSTANCE_IP "cd /opt/lucendex/docker && docker compose up -d"
    log_info "âœ“ Services started"

    # Wait for PostgreSQL
    log_info ""
    log_step "Waiting for PostgreSQL..."
    sleep 15
    
    # Wait for PostgreSQL to be ready to accept connections
    log_info "Waiting for PostgreSQL to accept connections..."
    for i in {1..40}; do
        if ssh -i data_services_ssh_key root@$INSTANCE_IP "docker exec lucendex-postgres pg_isready -U postgres" &> /dev/null; then
            log_info "âœ“ PostgreSQL is ready"
            break
        fi
        if [ $i -eq 1 ]; then
            echo -n "Initializing database"
        else
            echo -n "."
        fi
        sleep 3
    done
    echo ""

    # Apply database schema and migrations
    log_info ""
    log_step "Applying database schema and migrations..."
    
    # Copy files to VM
    scp -i data_services_ssh_key "$SCRIPT_DIR/../../backend/db/schema.sql" root@$INSTANCE_IP:/tmp/schema.sql
    scp -i data_services_ssh_key "$SCRIPT_DIR/../../backend/db/migrations/"*.sql root@$INSTANCE_IP:/tmp/
    
    # Copy into container and run
    ssh -i data_services_ssh_key root@$INSTANCE_IP << EOF
# Copy SQL files into container
docker cp /tmp/schema.sql lucendex-postgres:/tmp/
docker cp /tmp/001_amm_pools.sql lucendex-postgres:/tmp/
docker cp /tmp/002_orderbook_state.sql lucendex-postgres:/tmp/
docker cp /tmp/003_ledger_checkpoints.sql lucendex-postgres:/tmp/

# Run schema with password substitution
docker exec lucendex-postgres psql -U postgres -d lucendex \
  -v indexer_password="${TF_VAR_indexer_db_password}" \
  -v router_password="${TF_VAR_router_db_password}" \
  -v api_password="${TF_VAR_api_db_password}" \
  -f /tmp/schema.sql

# Run migrations
docker exec lucendex-postgres psql -U postgres -d lucendex -f /tmp/001_amm_pools.sql
docker exec lucendex-postgres psql -U postgres -d lucendex -f /tmp/002_orderbook_state.sql
docker exec lucendex-postgres psql -U postgres -d lucendex -f /tmp/003_ledger_checkpoints.sql
EOF
    log_info "âœ“ Database schema and migrations applied"
    
    # Display deployment info
    echo ""
    log_info "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    log_info "ðŸŽ‰ Data Services Deployment Complete!"
    log_info "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    log_info "Instance IP: $INSTANCE_IP"
    log_info "SSH: ssh -i $TERRAFORM_DIR/data_services_ssh_key root@$INSTANCE_IP"
    echo ""
    log_info "Services:"
    log_info "  - rippled API RPC: http://$INSTANCE_IP:51234"
    log_info "  - rippled API WebSocket: ws://$INSTANCE_IP:6005"
    log_info "  - PostgreSQL: $INSTANCE_IP:5432 (internal only)"
    echo ""
    log_info "Next steps:"
    log_info "  1. Wait for rippled nodes to sync: make data-sync-history"
    log_info "  2. Deploy indexer: make indexer-deploy"
    log_info "  3. Monitor: make indexer-logs"
    echo ""
    log_info "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
}

main "$@"
